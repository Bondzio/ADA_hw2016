{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = path.dirname('hillary-clinton-emails/')\n",
    "\n",
    "# Read the whole text.\n",
    "text = open(path.join(d, 'Emails.csv'),encoding='utf8').read()\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# lower max_font_size\n",
    "wordcloud = WordCloud(max_font_size=40).generate(text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('hillary-clinton-emails/Emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7945, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DocNumber</th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataTo</th>\n",
       "      <th>MetadataFrom</th>\n",
       "      <th>SenderPersonId</th>\n",
       "      <th>MetadataDateSent</th>\n",
       "      <th>MetadataDateReleased</th>\n",
       "      <th>MetadataPdfLink</th>\n",
       "      <th>MetadataCaseNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>ExtractedTo</th>\n",
       "      <th>ExtractedFrom</th>\n",
       "      <th>ExtractedCc</th>\n",
       "      <th>ExtractedDateSent</th>\n",
       "      <th>ExtractedCaseNumber</th>\n",
       "      <th>ExtractedDocNumber</th>\n",
       "      <th>ExtractedDateReleased</th>\n",
       "      <th>ExtractedReleaseInPartOrFull</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>RawText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>WOW</td>\n",
       "      <td>H</td>\n",
       "      <td>Sullivan, Jacob J</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sullivan, Jacob J &lt;Sullivan11@state.gov&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday, September 12, 2012 10:16 AM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  DocNumber MetadataSubject MetadataTo       MetadataFrom  \\\n",
       "0   1  C05739545             WOW          H  Sullivan, Jacob J   \n",
       "\n",
       "   SenderPersonId           MetadataDateSent       MetadataDateReleased  \\\n",
       "0            87.0  2012-09-12T04:00:00+00:00  2015-05-22T04:00:00+00:00   \n",
       "\n",
       "                                     MetadataPdfLink MetadataCaseNumber  \\\n",
       "0  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...       F-2015-04841   \n",
       "\n",
       "                         ...                         ExtractedTo  \\\n",
       "0                        ...                                 NaN   \n",
       "\n",
       "                              ExtractedFrom ExtractedCc  \\\n",
       "0  Sullivan, Jacob J <Sullivan11@state.gov>         NaN   \n",
       "\n",
       "                        ExtractedDateSent ExtractedCaseNumber  \\\n",
       "0  Wednesday, September 12, 2012 10:16 AM        F-2015-04841   \n",
       "\n",
       "  ExtractedDocNumber ExtractedDateReleased ExtractedReleaseInPartOrFull  \\\n",
       "0          C05739545            05/13/2015              RELEASE IN FULL   \n",
       "\n",
       "  ExtractedBodyText                                            RawText  \n",
       "0               NaN  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization of RawText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.ExtractedBodyTextString=df.ExtractedBodyText.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence=\"\".join(df.ExtractedBodyTextString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3645959"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "689100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; White House; State Department; FOIA WAIVER; BENGHAZI\n",
      "COMM; SELECT BENGHAZI; HOUSE SELECT; SENSITIVE INFORMATION;\n",
      "F-2015-04841 Doc; STATE DEPT; 05/13/2015 STATE; Private Residence; New\n",
      "York; *En route; State Case; OFFICE TIME; U.S. Department; health\n",
      "care; Middle East; Conference Room\n"
     ]
    }
   ],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont=0\n",
    "for i in tokens:\n",
    "    if i in stop:\n",
    "        cont+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220707"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_tokens=[x for x in tokens if x not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468393"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; White House; State Department; FOIA WAIVER; BENGHAZI\n",
      "COMM; SELECT BENGHAZI; HOUSE SELECT; SENSITIVE INFORMATION;\n",
      "F-2015-04841 Doc; STATE DEPT; 05/13/2015 STATE; Private Residence; New\n",
      "York; *En route; State Case; OFFICE TIME; U.S. Department; health\n",
      "care; Middle East; Conference Room\n"
     ]
    }
   ],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmed_tokens=[lmtzr.lemmatize(x) for x in good_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468393"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; White House; State Department; FOIA WAIVER; BENGHAZI\n",
      "COMM; SELECT BENGHAZI; HOUSE SELECT; SENSITIVE INFORMATION;\n",
      "F-2015-04841 Doc; STATE DEPT; 05/13/2015 STATE; Private Residence; New\n",
      "York; *En route; State Case; OFFICE TIME; U.S. Department; health\n",
      "care; Middle East; Conference Room\n"
     ]
    }
   ],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_string=' '.join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud().generate(final_string)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# lower max_font_size\n",
    "wordcloud = WordCloud(max_font_size=40).generate(final_string)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import at first the cleaned body text from a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hillary-clinton-emails/sentimentEmails.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at the dataset before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    6453\n",
       "True        3\n",
       "Name: ProcessedData, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ProcessedData.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there are NaNs left, we will wipe them out when building the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we define a list of stopwords to be wiped out from the documents; this words are typical English language stopwords or some trivial expressions which are contained in the *RawText*, such as 'fw:', 'sent:', 'from:', 'to:' (mail parameters) or 'u.s.', 'state', 'department' and so on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clear the documents from trivial recurrent words and from punctuation symbols\n",
    "\n",
    "punctuation_symbols = ['.',',',';',':','-','•','\"',\"'\",'?','!','@','#','/','*','+','(',')','—','{','}',\n",
    "                      '.\"',',\"','),','(,','<','>','%','&','$','---','----','-----','------','[',']',\n",
    "                      '■','--','...','://']\n",
    "trivial_words = ['u','w','h','j','us','fyi','would','fw','get']\n",
    "\n",
    "# here we decide to eliminate small numbers, as they prevent from a clear interpretation of the text\n",
    "# only 'great' ones (that is dates, likely) remain in the corpus\n",
    "numbs = range(100)\n",
    "numbers = [str(n) for n in numbs]\n",
    "numbers = list(set(numbers).union(set(['00'])))\n",
    "\n",
    "stoplist = list(set(trivial_words).union(set(punctuation_symbols).union(set(numbers))))\n",
    "\n",
    "# apply the stoplist to each document in RawText\n",
    "documents = [[word for word in text.lower().split() if word not in stoplist]\n",
    "            for text in df.ProcessedData.dropna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import the *gensim* library and define a **dictionary**, which matches any word in each text with a numeric ID; notice that the documents are treated as *bows* (numeric vectors); the output of this operation is the **corpus** we will perform analysis on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a dictionary to associate ad Id to each token and build the corpus\n",
    "from gensim import corpora, models\n",
    "dictionary = corpora.Dictionary(documents)\n",
    "corpus = [dictionary.doc2bow(text) for text in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the Latent Dirichlet Allocation using the dictionary and the corpus. Num_topics = **20** seems a reasonable choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"today\" + 0.009*\"letter\" + 0.007*\"state\" + 0.006*\"vote\" + 0.006*\"2010\" + 0.005*\"party\" + 0.004*\"gov\" + 0.004*\"good\" + 0.004*\"branch\" + 0.003*\"dan\"'),\n",
       " (1,\n",
       "  '0.007*\"time\" + 0.005*\"try\" + 0.005*\"last\" + 0.004*\"issue\" + 0.004*\"state\" + 0.004*\"qddr\" + 0.004*\"come\" + 0.003*\"email\" + 0.003*\"like\" + 0.003*\"russia\"'),\n",
       " (2,\n",
       "  '0.005*\"right\" + 0.005*\"send\" + 0.004*\"ask\" + 0.004*\"speech\" + 0.004*\"give\" + 0.003*\"report\" + 0.003*\"tell\" + 0.003*\"follow\" + 0.003*\"bill\" + 0.003*\"come\"'),\n",
       " (3,\n",
       "  '0.010*\"obama\" + 0.009*\"president\" + 0.009*\"secretary\" + 0.009*\"israel\" + 0.007*\"office\" + 0.006*\"time\" + 0.006*\"state\" + 0.005*\"nuclear\" + 0.005*\"white\" + 0.005*\"israeli\"'),\n",
       " (4,\n",
       "  '0.027*\"secretary\" + 0.026*\"office\" + 0.023*\"state\" + 0.013*\"department\" + 0.011*\"room\" + 0.008*\"arrive\" + 0.008*\"route\" + 0.008*\"en\" + 0.007*\"depart\" + 0.007*\"time\"'),\n",
       " (5,\n",
       "  '0.006*\"bill\" + 0.005*\"good\" + 0.005*\"clinton\" + 0.005*\"book\" + 0.005*\"obama\" + 0.004*\"state\" + 0.004*\"could\" + 0.004*\"like\" + 0.003*\"time\" + 0.003*\"diplomacy\"'),\n",
       " (6,\n",
       "  '0.007*\"palin\" + 0.005*\"care\" + 0.005*\"state\" + 0.005*\"republicans\" + 0.005*\"obama\" + 0.004*\"health\" + 0.004*\"2010\" + 0.004*\"percent\" + 0.004*\"republican\" + 0.004*\"company\"'),\n",
       " (7,\n",
       "  '0.011*\"state\" + 0.005*\"unite\" + 0.005*\"people\" + 0.005*\"conflict\" + 0.005*\"american\" + 0.005*\"force\" + 0.004*\"government\" + 0.004*\"world\" + 0.004*\"support\" + 0.004*\"security\"'),\n",
       " (8,\n",
       "  '0.006*\"time\" + 0.006*\"party\" + 0.004*\"state\" + 0.004*\"china\" + 0.004*\"may\" + 0.003*\"take\" + 0.003*\"first\" + 0.003*\"leave\" + 0.003*\"obama\" + 0.003*\"labour\"'),\n",
       " (9,\n",
       "  '0.024*\"state\" + 0.023*\"2010\" + 0.022*\"gov\" + 0.016*\"b6\" + 0.012*\"pls\" + 0.010*\"com\" + 0.009*\"clintonemail\" + 0.009*\"cheryl\" + 0.008*\"print\" + 0.008*\"hrod17\"')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define an lda model using the previously defined dictionary\n",
    "no_topics = 10\n",
    "lda = models.ldamodel.LdaModel(corpus, id2word = dictionary, num_topics=no_topics)\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform now some technical operations to print the topics in a sufficiently readable way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['today  letter  state  vote  2010  party  gov  good  branch  dan',\n",
       " 'time  try  last  issue  state  qddr  come  email  like  russia',\n",
       " 'right  send  ask  speech  give  report  tell  follow  bill  come',\n",
       " 'obama  president  secretary  israel  office  time  state  nuclear  white  israeli',\n",
       " 'secretary  office  state  department  room  arrive  route  en  depart  time',\n",
       " 'bill  good  clinton  book  obama  state  could  like  time  diplomacy',\n",
       " 'palin  care  state  republicans  obama  health  2010  percent  republican  company',\n",
       " 'state  unite  people  conflict  american  force  government  world  support  security',\n",
       " 'time  party  state  china  may  take  first  leave  obama  labour',\n",
       " 'state  2010  gov  b6  pls  com  clintonemail  cheryl  print  hrod17']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = []\n",
    "for num in range(no_topics):\n",
    "    topic_prob = lda.show_topic(num)\n",
    "    topic = []\n",
    "    for word in range(len(topic_prob)):\n",
    "        topic.append(topic_prob[word][0])\n",
    "    topic = '  '.join(topic)\n",
    "    topics.append(topic)\n",
    "topics"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
