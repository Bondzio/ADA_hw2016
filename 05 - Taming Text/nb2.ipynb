{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = path.dirname('hillary-clinton-emails/')\n",
    "\n",
    "# Read the whole text.\n",
    "text = open(path.join(d, 'Emails.csv'),encoding='utf8').read()\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# lower max_font_size\n",
    "wordcloud = WordCloud(max_font_size=40).generate(text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('hillary-clinton-emails/Emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7945, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DocNumber</th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataTo</th>\n",
       "      <th>MetadataFrom</th>\n",
       "      <th>SenderPersonId</th>\n",
       "      <th>MetadataDateSent</th>\n",
       "      <th>MetadataDateReleased</th>\n",
       "      <th>MetadataPdfLink</th>\n",
       "      <th>MetadataCaseNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>ExtractedTo</th>\n",
       "      <th>ExtractedFrom</th>\n",
       "      <th>ExtractedCc</th>\n",
       "      <th>ExtractedDateSent</th>\n",
       "      <th>ExtractedCaseNumber</th>\n",
       "      <th>ExtractedDocNumber</th>\n",
       "      <th>ExtractedDateReleased</th>\n",
       "      <th>ExtractedReleaseInPartOrFull</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>RawText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>WOW</td>\n",
       "      <td>H</td>\n",
       "      <td>Sullivan, Jacob J</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sullivan, Jacob J &lt;Sullivan11@state.gov&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday, September 12, 2012 10:16 AM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  DocNumber MetadataSubject MetadataTo       MetadataFrom  \\\n",
       "0   1  C05739545             WOW          H  Sullivan, Jacob J   \n",
       "\n",
       "   SenderPersonId           MetadataDateSent       MetadataDateReleased  \\\n",
       "0            87.0  2012-09-12T04:00:00+00:00  2015-05-22T04:00:00+00:00   \n",
       "\n",
       "                                     MetadataPdfLink MetadataCaseNumber  \\\n",
       "0  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...       F-2015-04841   \n",
       "\n",
       "                         ...                         ExtractedTo  \\\n",
       "0                        ...                                 NaN   \n",
       "\n",
       "                              ExtractedFrom ExtractedCc  \\\n",
       "0  Sullivan, Jacob J <Sullivan11@state.gov>         NaN   \n",
       "\n",
       "                        ExtractedDateSent ExtractedCaseNumber  \\\n",
       "0  Wednesday, September 12, 2012 10:16 AM        F-2015-04841   \n",
       "\n",
       "  ExtractedDocNumber ExtractedDateReleased ExtractedReleaseInPartOrFull  \\\n",
       "0          C05739545            05/13/2015              RELEASE IN FULL   \n",
       "\n",
       "  ExtractedBodyText                                            RawText  \n",
       "0               NaN  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization of RawText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.ExtractedBodyTextString=df.ExtractedBodyText.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence=\"\".join(df.ExtractedBodyTextString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3645959"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "689100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; White House; State Department; FOIA WAIVER; BENGHAZI\n",
      "COMM; SELECT BENGHAZI; HOUSE SELECT; SENSITIVE INFORMATION;\n",
      "F-2015-04841 Doc; STATE DEPT; 05/13/2015 STATE; Private Residence; New\n",
      "York; *En route; State Case; OFFICE TIME; U.S. Department; health\n",
      "care; Middle East; Conference Room\n"
     ]
    }
   ],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont=0\n",
    "for i in tokens:\n",
    "    if i in stop:\n",
    "        cont+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220707"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_tokens=[x for x in tokens if x not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468393"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; White House; State Department; FOIA WAIVER; BENGHAZI\n",
      "COMM; SELECT BENGHAZI; HOUSE SELECT; SENSITIVE INFORMATION;\n",
      "F-2015-04841 Doc; STATE DEPT; 05/13/2015 STATE; Private Residence; New\n",
      "York; *En route; State Case; OFFICE TIME; U.S. Department; health\n",
      "care; Middle East; Conference Room\n"
     ]
    }
   ],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmed_tokens=[lmtzr.lemmatize(x) for x in good_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468393"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; White House; State Department; FOIA WAIVER; BENGHAZI\n",
      "COMM; SELECT BENGHAZI; HOUSE SELECT; SENSITIVE INFORMATION;\n",
      "F-2015-04841 Doc; STATE DEPT; 05/13/2015 STATE; Private Residence; New\n",
      "York; *En route; State Case; OFFICE TIME; U.S. Department; health\n",
      "care; Middle East; Conference Room\n"
     ]
    }
   ],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_string=' '.join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud().generate(final_string)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# lower max_font_size\n",
    "wordcloud = WordCloud(max_font_size=40).generate(final_string)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import at first the cleaned body text from a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hillary-clinton-emails/sentimentEmails.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at the dataset before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thx</td>\n",
       "      <td>CHRIS STEVENS</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H &lt;hrod17@clintonemail.com&gt;\\r\\nFriday, March 1...</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pis print.\\r\\n-•-...-^\\r\\nH &lt; hrod17@clintoner...</td>\n",
       "      <td>MEET THE RIGHT-WING EXTREMIST BEHIND ANTI-MUSL...</td>\n",
       "      <td>-0.9191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H &lt;hrod17@clintonemail.corn&gt;\\r\\nFriday, March ...</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FYI</td>\n",
       "      <td>SECRETARY'S REMARKS</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B6\\r\\nWednesday, September 12, 2012 6:16 PM\\r\\...</td>\n",
       "      <td>MORE ON LIBYA</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fyi\\r\\nB6\\r\\n— —</td>\n",
       "      <td>ABZ AN HBJ ON LIBYA AND WEST BANK/GAZA</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B6\\r\\nWednesday, September 12, 2012 6:16 PM\\r\\...</td>\n",
       "      <td>MORE ON LIBYA</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fyi</td>\n",
       "      <td>HEY</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   ExtractedBodyText  \\\n",
       "0  B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...   \n",
       "1                                                Thx   \n",
       "2  H <hrod17@clintonemail.com>\\r\\nFriday, March 1...   \n",
       "3  Pis print.\\r\\n-•-...-^\\r\\nH < hrod17@clintoner...   \n",
       "4  H <hrod17@clintonemail.corn>\\r\\nFriday, March ...   \n",
       "5                                                FYI   \n",
       "6  B6\\r\\nWednesday, September 12, 2012 6:16 PM\\r\\...   \n",
       "7                                   Fyi\\r\\nB6\\r\\n— —   \n",
       "8  B6\\r\\nWednesday, September 12, 2012 6:16 PM\\r\\...   \n",
       "9                                                Fyi   \n",
       "\n",
       "                                     MetadataSubject  Sentiment  \n",
       "0  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...     0.0000  \n",
       "1                                      CHRIS STEVENS     0.3612  \n",
       "2  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...     0.0000  \n",
       "3  MEET THE RIGHT-WING EXTREMIST BEHIND ANTI-MUSL...    -0.9191  \n",
       "4  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...     0.0000  \n",
       "5                                SECRETARY'S REMARKS     0.2023  \n",
       "6                                      MORE ON LIBYA     0.0000  \n",
       "7             ABZ AN HBJ ON LIBYA AND WEST BANK/GAZA     0.2023  \n",
       "8                                      MORE ON LIBYA     0.0000  \n",
       "9                                                HEY     0.2023  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we define a list of stopwords to be wiped out from the documents; this words are typical English language stopwords or some trivial expressions which are contained in the *RawText*, such as 'fw:', 'sent:', 'from:', 'to:' (mail parameters) or 'u.s.', 'state', 'department' and so on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clear the documents from trivial recurrent words\n",
    "# NOTE: 08/31/2015 is a recurrent date\n",
    "# f-2014-20439 is related to the department identification code or something similar\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "trivial_topics = ['date:','unclassified','from:','sent:','subject:','to:','state','department',\n",
    "                  'no.','doc','case','u.s.','fw:','f-2014-20439','08/31/2015',\n",
    "                 're:','cc:','h','j']\n",
    "\n",
    "punctuation_symbols = \", : ; . ' % & $ @ - ( ) — <  > • * / + -\".split()\n",
    "\n",
    "# add punctuation symbols to the stopwords into a new list called stoplist\n",
    "stoplist = list(set(stop).union(set(punctuation_symbols).union(trivial_topics)))\n",
    "\n",
    "# apply the stoplist to each document in RawText\n",
    "documents = [[word for word in text.lower().split() if word not in stoplist]\n",
    "            for text in df.ExtractedBodyText.dropna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import the *gensim* library and define a **dictionary**, which matches any word in each text with a numeric ID; notice that the documents are treated as *bows* (numeric vectors); the output of this operation is the **corpus** we will perform analysis on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:840: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "# define a dictionary to associate ad Id to each token and build the corpus\n",
    "from gensim import corpora, models\n",
    "dictionary = corpora.Dictionary(documents)\n",
    "corpus = [dictionary.doc2bow(text) for text in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the Latent Dirichlet Allocation using the dictionary and the corpus. Num_topics = **20** seems a reasonable choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define an lda model using the previously defined dictionary\n",
    "no_topics = 20\n",
    "lda = models.ldamodel.LdaModel(corpus, id2word = dictionary, num_topics=no_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform now some technical operations to print the topics in a sufficiently readable way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['israeli  book  israel  iraqi  richards  one  called  referring  recommend  obama',\n",
       " \"you'll  cloture  it?  agree  new  kerry  office  2010  pm  call\",\n",
       " 'new  would  american  one  people  united  president  obama  government  said',\n",
       " 'fyi  b6  thought  afghan  (202)  wjc  see  dc  <verveerms@state.gov>  book,',\n",
       " 'netanyahu  cameron  mr  israeli  russia  it.  miliband  speech  2010  david',\n",
       " 'prince  2010  also  part  sullivan,  sent  new  would  via  b6',\n",
       " 'hikers  fyi.  mr.  would  print  me.  missile  pls  ashton  nuclear',\n",
       " 'mr.  talks  would  know  call  could  sunday,  ■  give  pm',\n",
       " 'see  w  call  would  jake  could  know  pm  boehner  thanks',\n",
       " 'kurdish  new  would  f.  haitian  see  white  taliban  said  may',\n",
       " \"pm  secretary's  office  meeting  room  conference  private  route  depart  arrive\",\n",
       " \"pm  office  secretary's  arrive  route  depart  meeting  residence  private  *en\",\n",
       " 'people  red  new  one  women  american  even  work  president  would',\n",
       " '2010  b1  1.4(d)  cheryl  fyi  mills,  <millscd@state.gov>  december  pm  on:',\n",
       " '2  1  3  2010  part  percent  press  call  clips  dialogue',\n",
       " 'tax  republican  labour  would  party  palin  thx.  yes  senate  democrats',\n",
       " 'ok.  please  2010  richards  huma  cdm  get  abedin,  gender  prefer',\n",
       " 'talk  checking  b5  radio  pir  do?  arsenal  accords  per  m.',\n",
       " '2010  print.  <hrod17@clintonemail.com>  pls  pm  secretary  ed  pis  assistant  lona',\n",
       " \"call  would  like  know  get  see  ok  want  w  i'm\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = []\n",
    "for num in range(no_topics):\n",
    "    topic_prob = lda.show_topic(num)\n",
    "    topic = []\n",
    "    for word in range(len(topic_prob)):\n",
    "        topic.append(topic_prob[word][0])\n",
    "    topic = '  '.join(topic)\n",
    "    topics.append(topic)\n",
    "topics"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
