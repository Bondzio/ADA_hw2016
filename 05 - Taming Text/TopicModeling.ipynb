{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary import of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import at first the cleaned body text from a csv file, build up during the previous sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hillary-clinton-emails/sentimentEmails.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of the following attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentiment', 'SemiProcessedData', 'ProcessedData'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature we are interested in now is *ProcessedData*, where the cleaned textual information has been extracted. We check the eventual presence of NaN values in the dataset before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    6453\n",
       "True        3\n",
       "Name: ProcessedData, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ProcessedData.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there are NaNs left, we will wipe them out when building the corpus, as they cannot be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we define a list of stopwords to be wiped out from the documents; this words are typical English language stopwords or some trivial expressions, such as mail vocabulary tokens ('fw', 're'), \"small\" numbers (which often prevent from a clear understanding of the underlying message), basic words ('get','would') and well as punctuation symbols. \"High\" numbers represent likely years in dates and thus may contain useful information. Thereafter we define a list *documents* containing the split words of any text in *ProcessedData*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clear the documents from trivial recurrent words and from punctuation symbols\n",
    "\n",
    "punctuation_symbols = ['.',',',';',':','-','•','\"',\"'\",'?','!','@','#','/','*','+','(',')','—','{','}',\n",
    "                      '.\"',',\"','),','(,','<','>','%','&','$','---','----','-----','------','[',']',\n",
    "                      '■','--','...','://']\n",
    "trivial_words = ['u','w','h','j','us','fyi','would','fw','get']\n",
    "\n",
    "numbs = range(100)\n",
    "numbers = [str(n) for n in numbs]\n",
    "numbers = list(set(numbers).union(set(['00'])))\n",
    "\n",
    "stoplist = list(set(trivial_words).union(set(punctuation_symbols).union(set(numbers))))\n",
    "\n",
    "# apply the stoplist to each document in RawText\n",
    "documents = [[word for word in text.lower().split() if word not in stoplist]\n",
    "            for text in df.ProcessedData.dropna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import the *gensim* library and define a **dictionary**, which matches any word in each text with a numeric ID; notice that the documents are treated as *bows* (numeric vectors); the output of this operation is the **corpus** we will perform analysis on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a dictionary to associate ad Id to each token and build the corpus\n",
    "from gensim import corpora, models\n",
    "dictionary = corpora.Dictionary(documents)\n",
    "corpus = [dictionary.doc2bow(text) for text in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the Latent Dirichlet Allocation using the dictionary and the corpus. The parameter *no_topics* defines the number of topics the algorithm must identify throughout the corpus. The higher it is, the more specific the returned topics will appear. Here we have chosen no_topics = 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define an lda model using the previously defined dictionary\n",
    "no_topics = 20\n",
    "lda = models.ldamodel.LdaModel(corpus, id2word = dictionary, num_topics=no_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method of the LdaModel class allows to visualize the selected topics as a collection of (word,probability) pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  '0.010*\"state\" + 0.006*\"clinton\" + 0.006*\"obama\" + 0.005*\"report\" + 0.004*\"beck\" + 0.004*\"policy\" + 0.004*\"bill\" + 0.004*\"come\" + 0.004*\"white\" + 0.004*\"good\"'),\n",
       " (18,\n",
       "  '0.014*\"happy\" + 0.013*\"2010\" + 0.010*\"mod\" + 0.009*\"state\" + 0.008*\"good\" + 0.008*\"miliband\" + 0.007*\"branch\" + 0.007*\"birthday\" + 0.006*\"thank\" + 0.006*\"follow\"'),\n",
       " (6,\n",
       "  '0.023*\"diplomacy\" + 0.015*\"bloomberg\" + 0.009*\"qddr\" + 0.007*\"right\" + 0.007*\"women\" + 0.005*\"include\" + 0.005*\"state\" + 0.005*\"human\" + 0.005*\"time\" + 0.005*\"ashton\"'),\n",
       " (13,\n",
       "  '0.009*\"state\" + 0.009*\"diplomats\" + 0.009*\"blair\" + 0.008*\"leak\" + 0.007*\"email\" + 0.006*\"confidential\" + 0.006*\"tony\" + 0.005*\"department\" + 0.005*\"fco\" + 0.005*\"office\"'),\n",
       " (5,\n",
       "  '0.008*\"peace\" + 0.007*\"state\" + 0.007*\"pakistan\" + 0.006*\"roger\" + 0.005*\"unite\" + 0.004*\"american\" + 0.004*\"government\" + 0.004*\"leaders\" + 0.004*\"conflict\" + 0.004*\"climate\"'),\n",
       " (2,\n",
       "  '0.006*\"email\" + 0.006*\"mins\" + 0.006*\"modernization\" + 0.005*\"time\" + 0.005*\"stone\" + 0.005*\"mubarak\" + 0.005*\"great\" + 0.005*\"thx\" + 0.005*\"original\" + 0.004*\"newsweek\"'),\n",
       " (11,\n",
       "  '0.015*\"ok\" + 0.012*\"statement\" + 0.010*\"article\" + 0.010*\"gov\" + 0.009*\"send\" + 0.009*\"email\" + 0.009*\"state\" + 0.007*\"2010\" + 0.006*\"corker\" + 0.006*\"647\"'),\n",
       " (17,\n",
       "  '0.012*\"holbrooke\" + 0.008*\"start\" + 0.007*\"afghanistan\" + 0.007*\"vote\" + 0.006*\"update\" + 0.005*\"pak\" + 0.004*\"framework\" + 0.004*\"deal\" + 0.004*\"come\" + 0.004*\"weekend\"'),\n",
       " (3,\n",
       "  '0.051*\"secretary\" + 0.044*\"office\" + 0.024*\"state\" + 0.024*\"room\" + 0.017*\"department\" + 0.015*\"arrive\" + 0.014*\"route\" + 0.014*\"depart\" + 0.014*\"en\" + 0.013*\"conference\"'),\n",
       " (12,\n",
       "  '0.009*\"obama\" + 0.007*\"nuclear\" + 0.006*\"american\" + 0.006*\"president\" + 0.005*\"mr\" + 0.005*\"force\" + 0.005*\"war\" + 0.004*\"iran\" + 0.004*\"like\" + 0.004*\"iraq\"')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform now some technical operations to print the topics in a sufficiently readable way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['please  pis  time  print  colombia  memo  arizona  thank  israeli  autoreply',\n",
       " 'state  clinton  obama  report  beck  policy  bill  come  white  good',\n",
       " 'email  mins  modernization  time  stone  mubarak  great  thx  original  newsweek',\n",
       " 'secretary  office  state  room  department  arrive  route  depart  en  conference',\n",
       " 'state  government  people  support  obama  conflict  american  right  president  party',\n",
       " 'peace  state  pakistan  roger  unite  american  government  leaders  conflict  climate',\n",
       " 'diplomacy  bloomberg  qddr  right  women  include  state  human  time  ashton',\n",
       " '2010  state  gov  com  clintonemail  hrod17  pls  b6  december  print',\n",
       " 'aipac  today  update  anytime  speak  missiles  thank  traffic  state  anywhere',\n",
       " 'b  b6  b1  part  release  bill  yes  tomorrow  party  vote',\n",
       " 'speech  try  time  war  write  first  news  foreign  tell  become',\n",
       " 'ok  statement  article  gov  send  email  state  2010  corker  647',\n",
       " 'obama  nuclear  american  president  mr  force  war  iran  like  iraq',\n",
       " 'state  diplomats  blair  leak  email  confidential  tony  department  fco  office',\n",
       " 'state  taliban  force  time  support  people  party  haiti  could  military',\n",
       " 'doc  tomorrow  ok  2010  mtg  state  jack  ask  come  let',\n",
       " 'israel  state  israeli  cheryl  mill  bibi  tomorrow  gov  draft  palestinians',\n",
       " 'holbrooke  start  afghanistan  vote  update  pak  framework  deal  come  weekend',\n",
       " 'happy  2010  mod  state  good  miliband  branch  birthday  thank  follow',\n",
       " 'state  unite  department  treaty  people  force  propose  security  qddr  american']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = []\n",
    "for num in range(no_topics):\n",
    "    topic_prob = lda.show_topic(num)\n",
    "    topic = []\n",
    "    for word in range(len(topic_prob)):\n",
    "        topic.append(topic_prob[word][0])\n",
    "    topic = '  '.join(topic)\n",
    "    topics.append(topic)\n",
    "topics"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
