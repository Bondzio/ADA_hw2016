{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the needed modules\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests as req\n",
    "import numpy as np\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#request with Requests library, using Postman interceptor - empty IS-Academia form\n",
    "base_url = 'http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.filter?ww_i_reportModel=133685247'\n",
    "r = req.get(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define BeautifulSoup object to parse the html doc\n",
    "soup = bs(r.text,'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the HTML form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following the parameters model, section, academic year, academic cycle and season are parsed, so that each variable is linked to its corresponding numeric code through a dictionary. Thereafter, the parameters names are obtained as the IS_Academia form accepts them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ww_i_reportModelXsl': '133685271', 'ww_i_reportmodel': '133685247'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the model code\n",
    "parse_model = soup.find_all('input')\n",
    "model = {}\n",
    "html_model = 'ww_i_reportmodel'\n",
    "xls_model = 'ww_i_reportModelXsl'\n",
    "for ind in parse_model:\n",
    "    if ind['name']==html_model:\n",
    "        model[html_model]=ind['value']\n",
    "    if ind['name']==xls_model:\n",
    "        model[xls_model]=ind['value']\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Informatique': '249847'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the section Informatique\n",
    "section = {'Informatique' : soup.find('option',string='Informatique')['value']}\n",
    "section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2007-2008': '978181',\n",
       " '2008-2009': '978187',\n",
       " '2009-2010': '978195',\n",
       " '2010-2011': '39486325',\n",
       " '2011-2012': '123455150',\n",
       " '2012-2013': '123456101',\n",
       " '2013-2014': '213637754',\n",
       " '2014-2015': '213637922',\n",
       " '2015-2016': '213638028',\n",
       " '2016-2017': '355925344'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the academic year - loop over the years and find the code corresponding to the year string\n",
    "academic_year = {}\n",
    "for year in range(2007,2017):\n",
    "    period = str(year)+'-'+str(year+1)\n",
    "    academic_year[period] = soup.find('option', string = period)['value']\n",
    "academic_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bachelor semestre 1': '249108',\n",
       " 'Bachelor semestre 2': '249114',\n",
       " 'Bachelor semestre 3': '942155',\n",
       " 'Bachelor semestre 4': '942163',\n",
       " 'Bachelor semestre 5': '942120',\n",
       " 'Bachelor semestre 6': '942175',\n",
       " 'Master semestre 1': '2230106',\n",
       " 'Master semestre 2': '942192',\n",
       " 'Master semestre 3': '2230128',\n",
       " 'Master semestre 4': '2230140',\n",
       " 'Projet Master automne': '249127',\n",
       " 'Projet Master printemps': '3781783'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the academic cycle - define the sought cycles and look for the corresponding codes, as above\n",
    "bachelor = []\n",
    "master = []\n",
    "for j in range(1,7):\n",
    "    bachelor.append('Bachelor semestre '+str(j))\n",
    "for j in range(1,5):\n",
    "    master.append('Master semestre '+str(j))\n",
    "bachelor_master = bachelor+master\n",
    "\n",
    "# add the master projects\n",
    "bachelor_master.append('Projet Master automne')\n",
    "bachelor_master.append('Projet Master printemps')\n",
    "\n",
    "academic_cycle = {}\n",
    "for cycle in bachelor_master:\n",
    "    academic_cycle[cycle] = soup.find('option', string = cycle)['value']\n",
    "academic_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Semestre d'automne\": '2936286', 'Semestre de printemps': '2936295'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the academic season - same procedure as above (actually not necessary)\n",
    "season = {}\n",
    "season[\"Semestre d'automne\"]=soup.find('option', string = \"Semestre d'automne\")['value']\n",
    "season['Semestre de printemps']=soup.find('option', string = 'Semestre de printemps')['value']\n",
    "season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ww_x_UNITE_ACAD',\n",
       " 'ww_x_PERIODE_ACAD',\n",
       " 'ww_x_PERIODE_PEDAGO',\n",
       " 'ww_x_HIVERETE']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the variables' names to fill in the IS-Academia form\n",
    "variables = []\n",
    "args = soup.find_all('select')\n",
    "for var in args:\n",
    "    variables.append(var['name'])\n",
    "variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of the GPS identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crucial information to be retrieved is now the parameter 'ww_x_GPS', which identifies the table to be downloaded.\n",
    "\n",
    "We define a suitable function to \"hack\" the value of the variable ww_x_GPS. Let us consider the following example:\n",
    "\n",
    "class=\"ww_x_GPS\" href=\"javascript:void(0)\" onclick=\"loadReport('ww_x_GPS=1378362120');return false;\">Informatique, 2012-2013, Bachelor semestre 2\n",
    "\n",
    "The GPS code is reported within the call to the html function 'loadReport', which is called when clicking the dataset. The function captureGPS seeks for the equal sign '=' inside the round parentheses and stops before the apostrophe sign. Once got the value of ww_x_GPS, one can use it to perform a request to the IS-Academia server passing a proper base url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to detect the GPS code of the table\n",
    "# strong assumption of the string's structure!\n",
    "def captureGPS(string):\n",
    "    letter = 0\n",
    "    while(string[letter]!='='):\n",
    "        letter=letter+1 #advance up to the =\n",
    "    letter = letter+1 # reach the first number of the GPS code\n",
    "    GPS = string[letter]\n",
    "    letter = letter+1\n",
    "    while (string[letter]!=\"'\"):\n",
    "        GPS = GPS+string[letter]\n",
    "        letter = letter+1\n",
    "    return GPS\n",
    "\n",
    "GPS = 'ww_x_GPS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the tables from IS-Academia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin now the importation of all the tables from the server. We define lists containing the values of the required parameters (section, year, cycle) and then seek for the ww_x_GPS parameter of each single table. We thus define a dataframe object and append progressively the datasets with the methods provided by the Pandas library. The index of the resulting dataframe will be a combination of name and Sciper number, which is of course not unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the parameters to perform the requests\n",
    "year = []\n",
    "for j in range(2007,2017):\n",
    "    year.append(str(j)+'-'+str(j+1))\n",
    "\n",
    "# the periods list has already been defined during the parsing operations\n",
    "#bachelor_master\n",
    "\n",
    "course = 'Informatique'\n",
    "\n",
    "# model variables have already been defined\n",
    "# html_model, xls_model\n",
    "\n",
    "dataset = pd.DataFrame(); #empty dataframe where to append all the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year: 2007-2008 parsed\n",
      "year: 2008-2009 parsed\n",
      "year: 2009-2010 parsed\n",
      "year: 2010-2011 parsed\n",
      "year: 2011-2012 parsed\n",
      "year: 2012-2013 parsed\n",
      "year: 2013-2014 parsed\n",
      "year: 2014-2015 parsed\n",
      "year: 2015-2016 parsed\n",
      "year: 2016-2017 parsed\n",
      "Finished parsing\n"
     ]
    }
   ],
   "source": [
    "# for now, only one year\n",
    "request_url = 'http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.html?'\n",
    "base_url = 'http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.filter?ww_i_reportModel=133685247'\n",
    "\n",
    "for cur_year in year:\n",
    "    for cycle in bachelor_master: # loop over the bachelor and master cycles\n",
    "        # define a search dictionary using the previous variables\n",
    "        research_keys = {}\n",
    "        research_keys[variables[0]] = section[course]\n",
    "        research_keys[variables[1]] = academic_year[cur_year]\n",
    "        research_keys[variables[2]] = academic_cycle[cycle]\n",
    "        research_keys['ww_b_list'] = 1\n",
    "        research_keys['ww_x_HIVERETE'] = 'null' # not important to extract the season - linked to the cycle\n",
    "        research_keys[html_model] = model[html_model]\n",
    "        research_keys[xls_model] = model[xls_model]\n",
    "        \n",
    "        r0 = req.get(base_url, params = research_keys)\n",
    "        s0 = bs(r0.text,'lxml') # beautifulsoup object from where to extract the GPS parameter\n",
    "        \n",
    "        # check for correctness of the call to captureGPS - missing data might occur\n",
    "        if(len(s0.find_all('a')) > 0):\n",
    "            research_keys[GPS]=captureGPS(s0.find_all('a')[1]['onclick'])\n",
    "            r = req.get(request_url, params = research_keys)\n",
    "            s = bs(r.text,'lxml')\n",
    "    \n",
    "            # s is the beautifulsoup object pointing to the table where are interested in\n",
    "            # define the columns names\n",
    "            attributes_list = s.find_all('th')[2:]\n",
    "            attributes = []\n",
    "            for ind in attributes_list:\n",
    "                attributes.append(ind.contents[0])\n",
    "            \n",
    "            # import the dataframe and manipulate properly the layout\n",
    "            df = pd.read_html(r.url)\n",
    "            # ensure the dataframe is not empty, otherwise skip\n",
    "            if(df[0].shape[0]>1 & df[0].shape[1]>1):\n",
    "                df = df[0][3:] # data is a list of dataframes of length 1; remove the first 2 rows ad the last 2 empty columns\n",
    "                del df[11]\n",
    "                del df[12]\n",
    "                df.columns = attributes\n",
    "                df = df.set_index('No Sciper')\n",
    "            \n",
    "                # add year and cycle information\n",
    "                df['Période académique']=cycle\n",
    "                df['Année académique']=cur_year\n",
    "    \n",
    "                # append dataframe\n",
    "                dataset = dataset.append(df)\n",
    "        \n",
    "    # useful for the user to understand the underlying process\n",
    "    message = 'year: '+str(cur_year)+' parsed'\n",
    "    print(message)\n",
    "    \n",
    "print('Finished parsing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save dataframe to load it in another ipython notebook, for sake of clarity\n",
    "dataset.to_excel('dataISAcademia.xls',sheet_name='Sheet1')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
