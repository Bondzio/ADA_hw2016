{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset importation\n",
    "At first, we import the dataset in csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerShort</th>\n",
       "      <th>player</th>\n",
       "      <th>club</th>\n",
       "      <th>leagueCountry</th>\n",
       "      <th>birthday</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>position</th>\n",
       "      <th>games</th>\n",
       "      <th>victories</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2</th>\n",
       "      <th>refNum</th>\n",
       "      <th>refCountry</th>\n",
       "      <th>Alpha_3</th>\n",
       "      <th>meanIAT</th>\n",
       "      <th>nIAT</th>\n",
       "      <th>seIAT</th>\n",
       "      <th>meanExp</th>\n",
       "      <th>nExp</th>\n",
       "      <th>seExp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lucas-wilchez</td>\n",
       "      <td>Lucas Wilchez</td>\n",
       "      <td>Real Zaragoza</td>\n",
       "      <td>Spain</td>\n",
       "      <td>31.08.1983</td>\n",
       "      <td>177.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Attacking Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GRC</td>\n",
       "      <td>0.326391</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.002696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>john-utaka</td>\n",
       "      <td>John Utaka</td>\n",
       "      <td>Montpellier HSC</td>\n",
       "      <td>France</td>\n",
       "      <td>08.01.1982</td>\n",
       "      <td>179.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Right Winger</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>0.203375</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.010875</td>\n",
       "      <td>-0.204082</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.061504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdon-prats</td>\n",
       "      <td>Abdón Prats</td>\n",
       "      <td>RCD Mallorca</td>\n",
       "      <td>Spain</td>\n",
       "      <td>17.12.1992</td>\n",
       "      <td>181.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ESP</td>\n",
       "      <td>0.369894</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.588297</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pablo-mari</td>\n",
       "      <td>Pablo Marí</td>\n",
       "      <td>RCD Mallorca</td>\n",
       "      <td>Spain</td>\n",
       "      <td>31.08.1993</td>\n",
       "      <td>191.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ESP</td>\n",
       "      <td>0.369894</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.588297</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ruben-pena</td>\n",
       "      <td>Rubén Peña</td>\n",
       "      <td>Real Valladolid</td>\n",
       "      <td>Spain</td>\n",
       "      <td>18.07.1991</td>\n",
       "      <td>172.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Right Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ESP</td>\n",
       "      <td>0.369894</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.588297</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     playerShort         player             club leagueCountry    birthday  \\\n",
       "0  lucas-wilchez  Lucas Wilchez    Real Zaragoza         Spain  31.08.1983   \n",
       "1     john-utaka     John Utaka  Montpellier HSC        France  08.01.1982   \n",
       "2    abdon-prats    Abdón Prats     RCD Mallorca         Spain  17.12.1992   \n",
       "3     pablo-mari     Pablo Marí     RCD Mallorca         Spain  31.08.1993   \n",
       "4     ruben-pena     Rubén Peña  Real Valladolid         Spain  18.07.1991   \n",
       "\n",
       "   height  weight              position  games  victories    ...     rater2  \\\n",
       "0   177.0    72.0  Attacking Midfielder      1          0    ...       0.50   \n",
       "1   179.0    82.0          Right Winger      1          0    ...       0.75   \n",
       "2   181.0    79.0                   NaN      1          0    ...        NaN   \n",
       "3   191.0    87.0           Center Back      1          1    ...        NaN   \n",
       "4   172.0    70.0      Right Midfielder      1          1    ...        NaN   \n",
       "\n",
       "   refNum  refCountry  Alpha_3   meanIAT    nIAT     seIAT   meanExp    nExp  \\\n",
       "0       1           1      GRC  0.326391   712.0  0.000564  0.396000   750.0   \n",
       "1       2           2      ZMB  0.203375    40.0  0.010875 -0.204082    49.0   \n",
       "2       3           3      ESP  0.369894  1785.0  0.000229  0.588297  1897.0   \n",
       "3       3           3      ESP  0.369894  1785.0  0.000229  0.588297  1897.0   \n",
       "4       3           3      ESP  0.369894  1785.0  0.000229  0.588297  1897.0   \n",
       "\n",
       "      seExp  \n",
       "0  0.002696  \n",
       "1  0.061504  \n",
       "2  0.001002  \n",
       "3  0.001002  \n",
       "4  0.001002  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('CrowdstormingDataJuly1st.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminating missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some rating labels are missing we consider for the training dataset the players with both ratings.\n",
    "Note that there are no players with a single rating missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_rater_data=data[data.rater2.isnull() & data.rater1.isnull()]\n",
    "rater_data=data[data.rater2.notnull() & data.rater1.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124621, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rater_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21407, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_rater_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146028, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    " - Delete the column photoID\n",
    " - Delete all the rows corresponding to a referee with less than 22 entry (impossible - problem in the dataset)\n",
    " - Remove less significant referee entry (with nIAT and nExp too low) [preprocess_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_1(database,remove_bad_referee=True,nIAT_threshold=50,nExp_threshold=50):\n",
    "    train=database.copy()\n",
    "    del train['photoID']\n",
    "    del train['victories']\n",
    "    del train['ties']\n",
    "    del train['defeats']\n",
    "    train['meanYellow']=train.yellowCards/train.games\n",
    "    train['meanReds']=train.redCards/train.games\n",
    "    train['meanYellowReds']=train.yellowReds/train.games\n",
    "\n",
    "    train_group=train.groupby(train.refNum)\n",
    "    \n",
    "    if remove_bad_referee:\n",
    "        for i,group in train_group:\n",
    "            if group.shape[0]<22:\n",
    "                train=train.drop(train_group.get_group(i).index)\n",
    "            if i%500==0:\n",
    "                print(i)\n",
    "    \n",
    "   \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "train_after_prep_1=preprocess_1(rater_data,remove_bad_referee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_2(database,nIAT_threshold=50,nExp_threshold=50):\n",
    "    train=database.copy()\n",
    "    train_group=database.groupby(train.refNum)\n",
    "\n",
    "    for i,group in train_group:\n",
    "        if group.nIAT.iloc[0]<nIAT_threshold or group.nExp.iloc[0]<nExp_threshold:\n",
    "            train=train.drop(train_group.get_group(i).index)\n",
    "        if i%200==0:\n",
    "            print(i)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "2400\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "train_after_prep_2=preprocess_2(train_after_prep_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_after_prep_2['IAT_yellow']=train_after_prep_2.meanYellow*train_after_prep_2.meanIAT\n",
    "# train_after_prep_2['IAT_yellowred']=train_after_prep_2.meanYellowReds*train_after_prep_2.meanIAT\n",
    "# train_after_prep_2['IAT_red']=train_after_prep_2.meanReds*train_after_prep_2.meanIAT\n",
    "# train_after_prep_2['Exp_yellow']=train_after_prep_2.meanYellow*train_after_prep_2.meanExp\n",
    "# train_after_prep_2['Exp_yellowred']=train_after_prep_2.meanYellowReds*train_after_prep_2.meanExp\n",
    "# train_after_prep_2['Exp_red']=train_after_prep_2.meanReds*train_after_prep_2.meanExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerShort</th>\n",
       "      <th>player</th>\n",
       "      <th>club</th>\n",
       "      <th>leagueCountry</th>\n",
       "      <th>birthday</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>position</th>\n",
       "      <th>games</th>\n",
       "      <th>goals</th>\n",
       "      <th>yellowCards</th>\n",
       "      <th>yellowReds</th>\n",
       "      <th>redCards</th>\n",
       "      <th>rater1</th>\n",
       "      <th>rater2</th>\n",
       "      <th>refNum</th>\n",
       "      <th>refCountry</th>\n",
       "      <th>Alpha_3</th>\n",
       "      <th>meanIAT</th>\n",
       "      <th>nIAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aaron-hughes</td>\n",
       "      <td>Aaron Hughes</td>\n",
       "      <td>Fulham FC</td>\n",
       "      <td>England</td>\n",
       "      <td>08.11.1979</td>\n",
       "      <td>182.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>LUX</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aleksandar-kolarov</td>\n",
       "      <td>Aleksandar Kolarov</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>England</td>\n",
       "      <td>10.11.1985</td>\n",
       "      <td>187.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Left Fullback</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>LUX</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alexander-tettey</td>\n",
       "      <td>Alexander Tettey</td>\n",
       "      <td>Norwich City</td>\n",
       "      <td>England</td>\n",
       "      <td>04.04.1986</td>\n",
       "      <td>180.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Defensive Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>LUX</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          playerShort              player             club leagueCountry  \\\n",
       "5        aaron-hughes        Aaron Hughes        Fulham FC       England   \n",
       "6  aleksandar-kolarov  Aleksandar Kolarov  Manchester City       England   \n",
       "7    alexander-tettey    Alexander Tettey     Norwich City       England   \n",
       "\n",
       "     birthday  height  weight              position  games  goals  \\\n",
       "5  08.11.1979   182.0    71.0           Center Back      1      0   \n",
       "6  10.11.1985   187.0    80.0         Left Fullback      1      0   \n",
       "7  04.04.1986   180.0    68.0  Defensive Midfielder      1      0   \n",
       "\n",
       "   yellowCards  yellowReds  redCards  rater1  rater2  refNum  refCountry  \\\n",
       "5            0           0         0    0.25    0.00       4           4   \n",
       "6            0           0         0    0.00    0.25       4           4   \n",
       "7            0           0         0    1.00    1.00       4           4   \n",
       "\n",
       "  Alpha_3   meanIAT   nIAT  \n",
       "5     LUX  0.325185  127.0  \n",
       "6     LUX  0.325185  127.0  \n",
       "7     LUX  0.325185  127.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_after_prep_2.ix[:,:20].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seIAT</th>\n",
       "      <th>meanExp</th>\n",
       "      <th>nExp</th>\n",
       "      <th>seExp</th>\n",
       "      <th>meanYellow</th>\n",
       "      <th>meanReds</th>\n",
       "      <th>meanYellowReds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      seIAT   meanExp   nExp     seExp  meanYellow  meanReds  meanYellowReds\n",
       "5  0.003297  0.538462  130.0  0.013752         0.0       0.0             0.0\n",
       "6  0.003297  0.538462  130.0  0.013752         0.0       0.0             0.0\n",
       "7  0.003297  0.538462  130.0  0.013752         0.0       0.0             0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_after_prep_2.ix[:,20:].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.0    77\n",
       "69.0    37\n",
       "76.0    28\n",
       "Name: nExp, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_after_prep_2.nExp[train_after_prep_2.nExp<100]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(train_after_prep_2.nExp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest with referee information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations done:\n",
    " - Keep only the wanted features: ['playerShort','leagueCountry','birthday','height','weight','position','games','club','yellowCards','redCards','yellowReds','meanIAT','meanExp','rater1','rater2']\n",
    " - Fill NaN with median of the columns\n",
    " - Keep only the year of birth (not the date)\n",
    " - Add dummy variables for the categorical variables\n",
    " - Keep one entry for player\n",
    " - Extract y as mean of the rater1 and rater2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting - adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_mean_player(x):\n",
    "    x_games=sum(x.games)\n",
    "    x['meanYellowPlayer']=sum(x.yellowCards)/x_games\n",
    "    x['meanRedPlayer']=sum(x.redCards)/x_games\n",
    "    x['meanYellowRedPlayer']=sum(x.yellowReds)/x_games\n",
    "    \n",
    "    x['meanYellowPlayerIAT']=sum(x.yellowCards*x.meanIAT)/x_games\n",
    "    x['meanRedPlayerIAT']=sum(x.redCards*x.meanIAT)/x_games\n",
    "    x['meanYellowRedPlayerIAT']=sum(x.yellowReds*x.meanIAT)/x_games\n",
    "    \n",
    "    x['meanYellowPlayerExp']=sum(x.yellowCards*x.meanExp)/x_games\n",
    "    x['meanRedPlayerExp']=sum(x.redCards*x.meanExp)/x_games\n",
    "    x['meanYellowRedPlayerExp']=sum(x.yellowReds*x.meanExp)/x_games\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_mean_role(x,train_database_grouped=False,is_train=True):\n",
    "    if is_train:\n",
    "        \n",
    "        x['meanYellowRole']=sum(x.yellowCards)/sum(x.games)\n",
    "        x['meanRedRole']=sum(x.redCards)/sum(x.games)\n",
    "        x['meanYellowRedRole']=sum(x.yellowReds)/sum(x.games)\n",
    "\n",
    "        x['meanYellowRoleIAT']=sum(x.yellowCards*x.meanIAT)/sum(x.games)\n",
    "        x['meanRedRoleIAT']=sum(x.redCards*x.meanIAT)/sum(x.games)\n",
    "        x['meanYellowRedRoleIAT']=sum(x.yellowReds*x.meanIAT)/sum(x.games)\n",
    "\n",
    "        x['meanYellowRoleExp']=sum(x.yellowCards*x.meanExp)/sum(x.games)\n",
    "        x['meanRedRoleExp']=sum(x.redCards*x.meanExp)/sum(x.games)\n",
    "        x['meanYellowRedRoleExp']=sum(x.yellowReds*x.meanExp)/sum(x.games)\n",
    "    else:\n",
    "        position=x.position.iloc[0]\n",
    "        leagueCountry=x.leagueCountry.iloc[0]\n",
    "        group=train_database_grouped.loc[position]\n",
    "        x['meanYellowRole']=group.loc['meanYellowRole']\n",
    "        x['meanRedRole']=group.loc['meanRedRole']\n",
    "        x['meanYellowRedRole']=group.loc['meanYellowRedRole']\n",
    "\n",
    "        x['meanYellowRoleIAT']=group.loc['meanYellowRoleIAT']\n",
    "        x['meanRedRoleIAT']=group.loc['meanRedRoleIAT']\n",
    "        x['meanYellowRedRoleIAT']=group.loc['meanYellowRedRoleIAT']\n",
    "\n",
    "        x['meanYellowRoleExp']=group.loc['meanYellowRoleExp']\n",
    "        x['meanRedRoleExp']=group.loc['meanRedRoleExp']\n",
    "        x['meanYellowRedRoleExp']=group.loc['meanYellowRedRoleExp']\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_database(starting_database,train_indexes=True,test=False,binary_y=False):\n",
    "    ''' Function that takes the preprocessed database and outputs train, test and y\n",
    "        @ params:\n",
    "            starting_database - the preprocessed database\n",
    "            train_indexes - the indexes of the player to be inserted in the training \n",
    "                            (the PLAYER INDEXES, not the indexes of the full database)\n",
    "            test - if considering also a test matrix\n",
    "            binary_y - if considering a binary (0-1) y\n",
    "                            \n",
    "        @ returns:\n",
    "            train\n",
    "            test\n",
    "            y\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    number_of_players=len(starting_database.playerShort.value_counts())\n",
    "    if test==False:\n",
    "        train_indexes=np.range(starting_database.shape[0])\n",
    "        test_indexes=[]\n",
    "    else:\n",
    "        small_database=starting_database.groupby('playerShort').mean()\n",
    "        small_database=small_database.iloc[train_indexes]\n",
    "        train_indexes=np.array(starting_database[starting_database.playerShort.isin(small_database.index)].index)\n",
    "        test_indexes=np.array(starting_database.index)\n",
    "        test_indexes=np.setdiff1d(test_indexes,train_indexes)\n",
    "    t1=time.time()\n",
    "    \n",
    "    # Keep only wanted features - remove nan\n",
    "    database=starting_database[['playerShort','leagueCountry','birthday','height','weight','position','games','club','yellowCards','redCards','yellowReds','meanIAT','meanExp','rater1','rater2']]\n",
    "    database.is_copy=False\n",
    "    database.position.fillna('nan',inplace=True)\n",
    "    database.leagueCountry.fillna('nan',inplace=True)\n",
    "    \n",
    "    database=database.fillna(database.loc[train_indexes].median())\n",
    "\n",
    "    # Process birthday to keep only the year\n",
    "    database.birthday=database.birthday.apply(lambda x: int(x.split('.')[2]))\n",
    "    \n",
    "    # Add features - mean yellow cards per match of each player and the same quantity weighted with IAT and Exp\n",
    "    database=database.groupby('playerShort').apply(add_mean_player)\n",
    "\n",
    "    # Add features - mean yellow cards per role (also the weighted quantity)\n",
    "    train_grouped=database.loc[train_indexes].groupby(['position']).apply(add_mean_role)\n",
    "    train_grouped=train_grouped.groupby(['position']).first()\n",
    "    database=database.groupby(['position']).apply(lambda x: add_mean_role(x,train_grouped,False))\n",
    "\n",
    "    # Difference of added features \n",
    "    database['yellowDifference']=database.meanYellowPlayer-database.meanYellowRole\n",
    "    database['redDifference']=database.meanRedPlayer-database.meanRedRole\n",
    "    database['yellowRedDifference']=database.meanYellowRedPlayer-database.meanYellowRedRole\n",
    "    \n",
    "    database['yellowDifferenceIAT']=database.meanYellowPlayerIAT-database.meanYellowRoleIAT\n",
    "    database['redDifferenceIAT']=database.meanRedPlayerIAT-database.meanRedRoleIAT\n",
    "    database['yellowRedDifferenceIAT']=database.meanYellowRedPlayerIAT-database.meanYellowRedRoleIAT\n",
    "    \n",
    "    database['yellowDifferenceExp']=database.meanYellowPlayerExp-database.meanYellowRoleExp\n",
    "    database['redDifferenceExp']=database.meanRedPlayerExp-database.meanRedRoleExp\n",
    "    database['yellowRedDifferenceExp']=database.meanYellowRedPlayerExp-database.meanYellowRedRoleExp\n",
    "    \n",
    "    # Dummy variables\n",
    "    dummy_variables=pd.get_dummies(database[['position','leagueCountry']])\n",
    "    database=pd.concat([database,dummy_variables],axis=1)\n",
    "    del database['leagueCountry']\n",
    "    del database['position']\n",
    "    \n",
    "    # Split train e test\n",
    "    train=database.loc[train_indexes]\n",
    "    test=database.loc[test_indexes]\n",
    "    \n",
    "    # Extract one row per player\n",
    "    train=train.groupby('playerShort').mean()\n",
    "    test=test.groupby('playerShort').mean()\n",
    "    \n",
    "    # Get y and delete the columns in the train\n",
    "    y_train=(train['rater1']+train['rater2'])/2\n",
    "    y_test=(test['rater1']+test['rater2'])/2\n",
    "    del train['rater1']\n",
    "    del train['rater2']\n",
    "    del test['rater1']\n",
    "    del test['rater2']\n",
    "\n",
    "    \n",
    "    # y assumes only 0-1 values\n",
    "    if binary_y:\n",
    "        y_train=1*(y_train>0.3)\n",
    "        y_test=1*(y_test>0.3)\n",
    "    return train,test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting in training and test database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_players=len(train_after_prep_2.playerShort.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = process_database(train_after_prep_2,train_indexes=np.random.randint(number_of_players,size=1000),test=True,binary_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_keep=['birthday', 'height', 'weight', \n",
    "                  'meanYellowPlayer', 'meanRedPlayer',\n",
    "       'meanYellowRedPlayer', 'meanYellowPlayerIAT', 'meanRedPlayerIAT',\n",
    "       'meanYellowRedPlayerIAT', 'meanYellowPlayerExp', 'meanRedPlayerExp',\n",
    "       'meanYellowRedPlayerExp', 'yellowDifference', 'redDifference',\n",
    "       'yellowRedDifference', 'yellowDifferenceIAT', 'redDifferenceIAT',\n",
    "       'yellowRedDifferenceIAT', 'yellowDifferenceExp', 'redDifferenceExp',\n",
    "       'yellowRedDifferenceExp',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train[features_to_keep]\n",
    "X_test=X_test[features_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_random_forest_model(X_train,X_test,y_train,y_test,n_estimators=10,criterion='gini',\n",
    "                                max_depth=None,min_samples_split=2, min_samples_leaf=1, \n",
    "              min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "              bootstrap=True, oob_score=False, n_jobs=1, random_state=None, \n",
    "              verbose=0, warm_start=False, class_weight=None):\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_estimators=n_estimators,criterion=criterion,\n",
    "                                max_depth=max_depth,min_samples_split=min_samples_split, \n",
    "                                                       min_samples_leaf=min_samples_leaf, \n",
    "                                                       min_weight_fraction_leaf=min_weight_fraction_leaf, \n",
    "                                                       max_features=max_features, max_leaf_nodes=max_leaf_nodes, \n",
    "                                                       bootstrap=bootstrap, \n",
    "                                                       oob_score=oob_score, n_jobs=n_jobs, random_state=random_state, \n",
    "                                                       verbose=verbose, warm_start=warm_start, \n",
    "                                                       class_weight=class_weight)\n",
    "    sample_weight=np.array([2.1 if i == 0 else 1 for i in y_train])\n",
    "    rfc.fit(X_train,np.asarray(y_train, dtype=\"|S6\"),sample_weight=sample_weight)\n",
    "    y_out=rfc.predict(X_test)\n",
    "    y_out=np.asarray(y_out,float)\n",
    "    y_out=np.asarray(8*y_out,int)\n",
    "    y_test=np.asarray(8*y_test,int)\n",
    "    y_out_binary=1*(y_out>0.3)\n",
    "    y_test_binary=1*(y_test>0.3)\n",
    "#     print((y_out-y_test)[:100])\n",
    "#     print(rfc.feature_importances_)\n",
    "    print(metrics.confusion_matrix(y_out_binary,y_test_binary))\n",
    "    return metrics.zero_one_loss(y_out_binary,y_test_binary)\n",
    "#     return metrics.mean_squared_error(y_out,y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting\n",
    "The first is the error with train and test split\n",
    "\n",
    "The second is the error evaluated in the train database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(y_test>0.3)/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_random_forest_model(X_train,X_test,y_train,y_test)\n",
    "# print(a,np.sum(a))\n",
    "# (np.sum(np.diagonal(a))+np.sum(np.diagonal(a,offset=-1))+np.sum(np.diagonal(a,offset=-2))+np.sum(np.diagonal(a,offset=2))+np.sum(np.diagonal(a,offset=1)))/np.sum(a)\n",
    "# (np.sum(np.diagonal(a))+np.sum(np.diagonal(a,offset=-1))+np.sum(np.diagonal(a,offset=1)))/np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_random_forest_model(X_train,X_train,y_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter variation to estimate overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_train=[]\n",
    "error_test=[]\n",
    "for i in range(1,20):\n",
    "    error_test.append(evaluate_random_forest_model(X_train,X_test,y_train,y_test,max_depth=i))\n",
    "    error_train.append(evaluate_random_forest_model(X_train,X_train,y_train,y_train,max_depth=i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,20),error_test)\n",
    "plt.plot(range(1,20),error_train)\n",
    "plt.legend(['test_error','train_error'])\n",
    "plt.title('Error with different max_depth')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('mean square error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_train=[]\n",
    "error_test=[]\n",
    "for i in range(1,40):\n",
    "    error_test.append(evaluate_random_forest_model(X_train,X_test,y_train,y_test,n_estimators=i))\n",
    "    error_train.append(evaluate_random_forest_model(X_train,X_train,y_train,y_train,n_estimators=i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,40),error_test)\n",
    "plt.plot(range(1,40),error_train)\n",
    "plt.legend(['test_error','train_error'])\n",
    "plt.title('Error with different n_estimators')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('mean square error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_train=[]\n",
    "error_test=[]\n",
    "\n",
    "error_test.append(evaluate_random_forest_model(X_train,X_test,y_train,y_test,criterion='gini'))\n",
    "error_train.append(evaluate_random_forest_model(X_train,X_train,y_train,y_train,criterion='gini'))\n",
    "\n",
    "error_test.append(evaluate_random_forest_model(X_train,X_test,y_train,y_test,criterion='entropy'))\n",
    "error_train.append(evaluate_random_forest_model(X_train,X_train,y_train,y_train,criterion='entropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With cross validation we expect more precise results.\n",
    "We chosed n_folds=30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(train.shape[0], n_folds=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_val(database,n_estimators=10,criterion='gini',\n",
    "                                max_depth=None,min_samples_split=2, min_samples_leaf=1, \n",
    "              min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "              bootstrap=True, oob_score=False, n_jobs=1, random_state=None, \n",
    "              verbose=0, warm_start=False, class_weight=None):\n",
    "    \n",
    "    error_train=[]\n",
    "    error_test=[]\n",
    "    for iteration, data in enumerate(kf, start=1):\n",
    "        print('Iteration:',iteration)\n",
    "#         X_train=database.iloc[data[0]]\n",
    "#         X_test=database.iloc[data[1]]\n",
    "#         y_train=output.iloc[data[0]]\n",
    "#         y_test=output.iloc[data[1]]\n",
    "\n",
    "        X_train,X_test,y_train,y_test=process_database(database,train_indexes=data[0],test=True,binary_y=True)\n",
    "        X_train=X_train[features_to_keep]\n",
    "        X_test=X_test[features_to_keep]\n",
    "        error_test.append(evaluate_random_forest_model(X_train,X_test,y_train,y_test,\n",
    "                                                       n_estimators=n_estimators,criterion=criterion,\n",
    "                                                       max_depth=max_depth,min_samples_split=min_samples_split, \n",
    "                                                       min_samples_leaf=min_samples_leaf, \n",
    "                                                       min_weight_fraction_leaf=min_weight_fraction_leaf, \n",
    "                                                       max_features=max_features, max_leaf_nodes=max_leaf_nodes, \n",
    "                                                       bootstrap=bootstrap, \n",
    "                                                       oob_score=oob_score, n_jobs=n_jobs, random_state=random_state, \n",
    "                                                       verbose=verbose, warm_start=warm_start, \n",
    "                                                       class_weight=class_weight))\n",
    "        error_train.append(evaluate_random_forest_model(X_train,X_train,y_train,y_train,\n",
    "                                                        n_estimators=n_estimators,criterion=criterion,\n",
    "                                                       max_depth=max_depth,min_samples_split=min_samples_split, \n",
    "                                                       min_samples_leaf=min_samples_leaf, \n",
    "                                                       min_weight_fraction_leaf=min_weight_fraction_leaf, \n",
    "                                                       max_features=max_features, max_leaf_nodes=max_leaf_nodes, \n",
    "                                                       bootstrap=bootstrap, \n",
    "                                                       oob_score=oob_score, n_jobs=n_jobs, random_state=random_state, \n",
    "                                                       verbose=verbose, warm_start=warm_start, \n",
    "                                                       class_weight=class_weight))\n",
    "    return np.mean(error_train),np.mean(error_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameters so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(y_test==1)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_val(train_after_prep_2,min_samples_leaf=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_train=[]\n",
    "error_test=[]\n",
    "# for i in np.linspace(0,0.5,40):\n",
    "for i in range(2,41):\n",
    "    error_train_,error_test_=cross_val(train,y_ref,max_depth=i,min_samples_leaf=20)\n",
    "    error_train.append(error_train_)\n",
    "    error_test.append(error_test_)\n",
    "    if i%10==0:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,40),error_test)\n",
    "plt.plot(range(1,40),error_train)\n",
    "plt.legend(['test_error','train_error'])\n",
    "plt.title('Error with different max_depth')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('mean square error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_train=[]\n",
    "error_test=[]\n",
    "for i in range(1,40):\n",
    "    error_train_,error_test_=cross_val(train,y_ref,n_estimators=i)\n",
    "    error_train.append(error_train_)\n",
    "    error_test.append(error_test_)\n",
    "    if i%10==0:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,40),error_test)\n",
    "plt.plot(range(1,40),error_train)\n",
    "plt.legend(['test_error','train_error'])\n",
    "plt.title('Error with different n_estimators')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('mean square error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_train=[]\n",
    "error_test=[]\n",
    "\n",
    "error_train_,error_test_=cross_val(train_trivial,y_trivial,criterion='gini')\n",
    "\n",
    "error_train.append(error_train_)\n",
    "error_test.append(error_test_)\n",
    "\n",
    "error_train_,error_test_=cross_val(train_trivial,y_trivial,criterion='entropy')\n",
    "\n",
    "error_train.append(error_train_)\n",
    "error_test.append(error_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
